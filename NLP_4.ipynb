{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: Devashish Mayur Potnis\n",
    "# Class: BE-AIML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1228,
     "status": "ok",
     "timestamp": 1705572727866,
     "user": {
      "displayName": "Adwait Deshpande",
      "userId": "14863366921114492910"
     },
     "user_tz": -330
    },
    "id": "aKKG8tX3A_7d",
    "outputId": "658edefa-c4b7-4aba-a47f-5ded5c08eeca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-8.7619e-02,  2.0156e-01,  2.8862e-01,  ..., -1.2939e+00,\n",
      "           5.1404e-01,  1.4258e+00],\n",
      "         [-3.0341e-02,  8.7924e-01, -9.7820e-01,  ...,  1.2920e+00,\n",
      "           2.9295e-01, -1.3277e+00],\n",
      "         [-1.5473e+00, -1.0971e-01,  4.6799e-01,  ...,  6.9329e-02,\n",
      "           9.3166e-01, -1.7259e+00],\n",
      "         ...,\n",
      "         [ 1.8971e-01, -1.0820e+00, -1.0425e+00,  ...,  8.1433e-01,\n",
      "           3.5505e-01, -1.1333e+00],\n",
      "         [-7.5087e-01, -2.2452e-02, -9.4044e-01,  ...,  9.3356e-01,\n",
      "           4.1222e+00, -8.2847e-01],\n",
      "         [-1.1959e+00, -3.3969e-02,  1.0555e+00,  ..., -1.1676e+00,\n",
      "           1.1279e+00, -1.2758e+00]],\n",
      "\n",
      "        [[-1.0027e+00, -6.4236e-01, -4.9098e-01,  ..., -2.2374e+00,\n",
      "           2.7833e-01,  1.6787e+00],\n",
      "         [ 2.9975e-01,  3.5225e-01,  2.0555e-01,  ...,  5.5566e-01,\n",
      "           4.9051e-01, -1.9905e+00],\n",
      "         [-1.3381e+00,  1.5946e-01,  4.2815e-02,  ..., -2.7201e-01,\n",
      "           1.3507e+00, -1.8895e+00],\n",
      "         ...,\n",
      "         [-8.8799e-01, -1.3638e+00, -3.6541e-01,  ...,  4.7852e-01,\n",
      "          -3.7682e-01, -5.4973e-01],\n",
      "         [-4.8617e-01, -2.4417e-01, -2.0006e+00,  ...,  1.1503e+00,\n",
      "           3.2727e+00, -2.0392e-01],\n",
      "         [-1.3196e+00,  1.3024e-01,  1.6553e-01,  ..., -9.9363e-01,\n",
      "           1.0993e+00, -4.8383e-01]],\n",
      "\n",
      "        [[-1.1477e+00,  1.0499e+00, -1.6467e-01,  ..., -1.3626e+00,\n",
      "           7.8475e-01,  2.0594e+00],\n",
      "         [ 7.2346e-01,  7.0061e-01,  6.9912e-02,  ...,  5.6502e-01,\n",
      "           9.3294e-01, -9.8928e-01],\n",
      "         [-1.4540e+00,  4.0988e-02,  4.3545e-02,  ..., -4.2403e-01,\n",
      "           9.2925e-01, -2.1879e+00],\n",
      "         ...,\n",
      "         [-4.6121e-01, -2.7659e-01,  1.0191e-01,  ...,  9.7433e-01,\n",
      "          -8.2723e-02, -8.8547e-01],\n",
      "         [ 2.8943e-01, -5.3925e-01, -1.6027e+00,  ...,  4.2274e-01,\n",
      "           3.5914e+00, -9.8782e-01],\n",
      "         [-8.0137e-01,  2.9738e-01,  9.1001e-01,  ..., -5.5778e-01,\n",
      "           1.4237e+00, -6.6438e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.6903e-01,  3.7688e-01,  5.3130e-02,  ..., -1.4721e+00,\n",
      "          -1.0535e-01,  2.3192e+00],\n",
      "         [ 7.2509e-02,  9.6371e-01,  5.0920e-03,  ...,  1.4756e+00,\n",
      "           4.3730e-01, -1.0766e+00],\n",
      "         [-1.5525e+00, -4.7474e-02,  1.1886e-01,  ..., -1.1384e+00,\n",
      "           1.5294e+00, -1.5140e+00],\n",
      "         ...,\n",
      "         [-6.1930e-01, -2.0973e-01, -1.9794e-01,  ...,  4.9088e-02,\n",
      "           4.5672e-01, -1.7486e+00],\n",
      "         [ 1.3986e+00,  5.3890e-01, -2.0105e+00,  ...,  1.3278e+00,\n",
      "           3.5877e+00, -9.2551e-01],\n",
      "         [-1.2885e+00,  1.4582e-01,  7.5578e-01,  ..., -1.2823e+00,\n",
      "           2.2368e+00, -5.0541e-01]],\n",
      "\n",
      "        [[-1.0789e+00,  4.1926e-01, -2.0862e-01,  ..., -1.3142e+00,\n",
      "           1.7577e-01,  7.5352e-01],\n",
      "         [-3.3627e-03,  1.1710e+00,  3.8927e-03,  ...,  5.3992e-01,\n",
      "           8.7998e-01, -8.7188e-01],\n",
      "         [-1.7795e+00, -2.7095e-01,  5.1323e-01,  ..., -6.0643e-01,\n",
      "           1.0398e+00, -1.9746e+00],\n",
      "         ...,\n",
      "         [-5.3223e-01, -1.0775e+00, -7.1993e-01,  ...,  9.5511e-01,\n",
      "           1.4854e-01, -1.1463e+00],\n",
      "         [ 6.3760e-01, -1.4919e-02, -1.4434e+00,  ...,  1.0473e+00,\n",
      "           4.0253e+00, -7.2330e-01],\n",
      "         [-1.5297e+00, -2.5935e-02,  7.3477e-01,  ..., -3.6548e-01,\n",
      "           1.2151e+00, -1.3604e+00]],\n",
      "\n",
      "        [[-9.9688e-01,  8.3238e-01,  4.5619e-01,  ..., -1.4873e+00,\n",
      "           6.4263e-01,  1.6614e+00],\n",
      "         [ 1.0632e-01,  7.8430e-01, -2.6207e-01,  ...,  1.5481e+00,\n",
      "           7.5506e-01, -7.0898e-01],\n",
      "         [-1.7770e+00, -5.0608e-02,  3.2617e-01,  ..., -2.6262e-01,\n",
      "           9.5394e-01, -1.8257e+00],\n",
      "         ...,\n",
      "         [-2.4008e-01, -1.4522e+00, -7.0834e-01,  ...,  3.0390e-01,\n",
      "          -2.7511e-01, -1.1566e+00],\n",
      "         [-8.2256e-01,  2.7601e-01, -1.7545e+00,  ...,  5.9646e-01,\n",
      "           4.5949e+00, -1.3389e+00],\n",
      "         [-1.2937e+00, -7.7849e-01,  7.4904e-01,  ..., -2.7060e-01,\n",
      "           1.8390e+00, -1.0199e+00]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "Output shape: torch.Size([16, 100, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_model // n_heads\n",
    "\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.fc_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, query, key, value, mask):\n",
    "        batch_size = query.shape[0]\n",
    "\n",
    "        # Linear transformations\n",
    "        Q = self.query(query)\n",
    "        K = self.key(key)\n",
    "        V = self.value(value)\n",
    "\n",
    "        # Split into heads\n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float('-1e20'))\n",
    "\n",
    "        attention = torch.nn.functional.softmax(energy, dim=-1)\n",
    "        x = torch.matmul(attention, V)\n",
    "\n",
    "        # Reshape and concatenate\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = x.view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # Final linear layer\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, ff_dim, dropout=0.1):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        self.self_attention = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, d_model)\n",
    "        )\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # Self-attention\n",
    "        attention = self.self_attention(x, x, x, mask)\n",
    "        x = x + self.dropout(attention)\n",
    "        x = self.layer_norm1(x)\n",
    "\n",
    "        # Feedforward\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = x + self.dropout(ffn_output)\n",
    "        x = self.layer_norm2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, ff_dim, n_layers, max_seq_length, dropout=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerEncoderLayer(d_model, n_heads, ff_dim, dropout)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.position_embedding = nn.Embedding(max_seq_length, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        positions = torch.arange(0, x.size(1)).expand(x.size(0), x.size(1)).to(self.device)\n",
    "        x = x + self.position_embedding(positions)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "d_model = 512\n",
    "n_heads = 8\n",
    "ff_dim = 2048\n",
    "n_layers = 6\n",
    "max_seq_length = 100\n",
    "dropout = 0.1\n",
    "\n",
    "# Create transformer encoder\n",
    "transformer_encoder = TransformerEncoder(d_model, n_heads, ff_dim, n_layers, max_seq_length, dropout)\n",
    "\n",
    "# Dummy input\n",
    "input_data = torch.rand((16, 100, d_model))\n",
    "\n",
    "# Mask for padding\n",
    "padding_mask = (input_data.sum(dim=-1) != 0).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "# Forward pass\n",
    "output_data = transformer_encoder(input_data, padding_mask)\n",
    "print(output_data)\n",
    "print(\"Output shape:\", output_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "executionInfo": {
     "elapsed": 633,
     "status": "error",
     "timestamp": 1705572679636,
     "user": {
      "displayName": "Adwait Deshpande",
      "userId": "14863366921114492910"
     },
     "user_tz": -330
    },
    "id": "PbmacPeqBpER",
    "outputId": "f0f2b3ee-1580-4539-973e-6dc0a1f54b7b"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (512) must match the size of tensor b (10) at non-singleton dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f7e5c62f41e5>\u001b[0m in \u001b[0;36m<cell line: 128>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f7e5c62f41e5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f7e5c62f41e5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# Multi-Head Self-Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f7e5c62f41e5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (10) at non-singleton dimension 4"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_model // n_heads\n",
    "\n",
    "        # Define linear layers for queries, keys, and values\n",
    "        self.linear_q = nn.Linear(d_model, d_model)\n",
    "        self.linear_k = nn.Linear(d_model, d_model)\n",
    "        self.linear_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Linear layer for the output of the attention heads\n",
    "        self.linear_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.shape[0]\n",
    "\n",
    "        # Linear transformation for queries, keys, and values\n",
    "        Q = self.linear_q(query)\n",
    "        K = self.linear_k(key)\n",
    "        V = self.linear_v(value)\n",
    "\n",
    "        # Split into multiple heads\n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim)\n",
    "\n",
    "        # Transpose to prepare for attention calculation\n",
    "        Q = Q.permute(0, 2, 1, 3)\n",
    "        K = K.permute(0, 2, 1, 3)\n",
    "        V = V.permute(0, 2, 1, 3)\n",
    "\n",
    "        # Calculate scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.permute(0, 1, 3, 2)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "        x = torch.matmul(attention, V)\n",
    "\n",
    "        # Concatenate attention heads\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        x = x.view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # Linear transformation for the output\n",
    "        x = self.linear_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, ff_hidden_dim):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, ff_hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear2 = nn.Linear(ff_hidden_dim, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, ff_hidden_dim):\n",
    "        super(TransformerLayer, self).__init__()\n",
    "\n",
    "        # Multi-Head Self-Attention\n",
    "        self.self_attention = MultiHeadAttention(d_model, n_heads)\n",
    "\n",
    "        # Feedforward Neural Network\n",
    "        self.feedforward = FeedForward(d_model, ff_hidden_dim)\n",
    "\n",
    "        # Layer normalization\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # Multi-Head Self-Attention\n",
    "        attention_output = self.self_attention(x, x, x, mask)\n",
    "        x = x + self.dropout(attention_output)\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        # Feedforward Neural Network\n",
    "        ff_output = self.feedforward(x)\n",
    "        x = x + self.dropout(ff_output)\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, ff_hidden_dim, n_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # Stack multiple transformer layers\n",
    "        self.layers = nn.ModuleList([TransformerLayer(d_model, n_heads, ff_hidden_dim) for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Example usage\n",
    "d_model = 512\n",
    "n_heads = 8\n",
    "ff_hidden_dim = 2048\n",
    "n_layers = 6\n",
    "\n",
    "# Create transformer model\n",
    "transformer = Transformer(d_model, n_heads, ff_hidden_dim, n_layers)\n",
    "\n",
    "# Dummy input\n",
    "input_data = torch.rand((32, 10, d_model))  # (batch_size, sequence_length, d_model)\n",
    "\n",
    "# Mask for padding tokens\n",
    "mask = (input_data != 0).unsqueeze(1).unsqueeze(2)  # Assuming 0 represents padding tokens\n",
    "\n",
    "# Forward pass\n",
    "output = transformer(input_data, mask)\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBxx9ITuBqfJ"
   },
   "outputs": [],
   "source": [
    "# Definition: A deep learning model architecture based on self-attention, widely used in NLP tasks.\n",
    "# Key Components:\n",
    "# Self-Attention: Computes attention scores among input tokens.\n",
    "# Positional Encoding: Adds positional information to input tokens.\n",
    "# Multi-Head Attention: Allows the model to focus on different parts of the input simultaneously.\n",
    "# Feed-Forward Networks: Apply additional transformation layers.\n",
    "# Layer Normalization: Normalizes the output of each layer to stabilize training."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO6tuwuCGLIUASC60NLOhGD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
